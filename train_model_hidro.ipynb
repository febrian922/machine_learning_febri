{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EZDxukSCzT05",
        "10fc5SdMzZo_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "ZbovbelEyvsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "5y4rKTZP3Ilv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Drive"
      ],
      "metadata": {
        "id": "uQZx-vN-yz_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6Vt0KFu3lZGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d729dbb-9527-4ff5-e91c-ba0230b8403b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdT_4qlAy--w"
      },
      "outputs": [],
      "source": [
        "# Define root directory\n",
        "dir_sehat = '/content/drive/MyDrive/new dataset/sehat'\n",
        "dir_sakit = '/content/drive/MyDrive/new dataset/sakit'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Training Validation Test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c8viWjCCzDvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk membuat Directory Training dan Validation\n",
        "\n",
        "kalau udh displit di drive, gausah displit lagi"
      ],
      "metadata": {
        "id": "AG9pg24Q7PiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(root_dir, train_size=0.95, val_size=0.1, test_size=0.05, random_seed=42):\n",
        "    # Membuat direktori untuk train, val, dan test\n",
        "    train_dir = os.path.join(root_dir, 'train')\n",
        "    val_dir = os.path.join(root_dir, 'val')\n",
        "    test_dir = os.path.join(root_dir, 'test')\n",
        "\n",
        "    # Membuat direktori train jika belum ada\n",
        "    if not os.path.exists(train_dir):\n",
        "        os.makedirs(train_dir)\n",
        "\n",
        "    # Membuat direktori val jika belum ada\n",
        "    if not os.path.exists(val_dir):\n",
        "        os.makedirs(val_dir)\n",
        "\n",
        "    # Membuat direktori test jika belum ada\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "\n",
        "    # Loop melalui setiap direktori (jenis tanaman)\n",
        "    for plant_type in os.listdir(root_dir):\n",
        "        if os.path.isdir(os.path.join(root_dir, plant_type)):\n",
        "            # Membuat sub-direktori untuk setiap jenis tanaman di setiap direktori (train, val, test)\n",
        "            train_plant_dir = os.path.join(train_dir, plant_type)\n",
        "            val_plant_dir = os.path.join(val_dir, plant_type)\n",
        "            test_plant_dir = os.path.join(test_dir, plant_type)\n",
        "\n",
        "            if not os.path.exists(train_plant_dir):\n",
        "                os.makedirs(train_plant_dir)\n",
        "\n",
        "            if not os.path.exists(val_plant_dir):\n",
        "                os.makedirs(val_plant_dir)\n",
        "\n",
        "            if not os.path.exists(test_plant_dir):\n",
        "                os.makedirs(test_plant_dir)\n",
        "\n",
        "            # Mengambil daftar file gambar untuk setiap jenis tanaman\n",
        "            plant_images = [img for img in os.listdir(os.path.join(root_dir, plant_type)) if os.path.isfile(os.path.join(root_dir, plant_type, img))]\n",
        "\n",
        "            # Membagi data menjadi train, val, dan test\n",
        "            train_images, test_images = train_test_split(plant_images, test_size=val_size + test_size, random_state=random_seed)\n",
        "            val_images, test_images = train_test_split(test_images, test_size=test_size/(val_size + test_size), random_state=random_seed)\n",
        "\n",
        "            # Memindahkan gambar ke dalam direktori yang sesuai\n",
        "            for image in train_images:\n",
        "                src_path = os.path.join(root_dir, plant_type, image)\n",
        "                dest_path = os.path.join(train_plant_dir, image)\n",
        "                shutil.copy(src_path, dest_path)\n",
        "\n",
        "            for image in val_images:\n",
        "                src_path = os.path.join(root_dir, plant_type, image)\n",
        "                dest_path = os.path.join(val_plant_dir, image)\n",
        "                shutil.copy(src_path, dest_path)\n",
        "\n",
        "            for image in test_images:\n",
        "                src_path = os.path.join(root_dir, plant_type, image)\n",
        "                dest_path = os.path.join(test_plant_dir, image)\n",
        "                shutil.copy(src_path, dest_path)"
      ],
      "metadata": {
        "id": "iDy3No1YxbU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    split_sehat = split_data(dir_sehat)\n",
        "    if len(split_sehat) == 0:\n",
        "        raise ValueError(\"No data found in the directory.\")\n",
        "    else:\n",
        "        print(\"Plant Label Map:\", split_sehat)\n",
        "    # Continue with the rest of your code\n",
        "except FileExistsError:\n",
        "    print(\"You should not be seeing this since the upper directory is removed beforehand\")\n",
        "except ValueError as ve:\n",
        "    print(ve)\n",
        "    # Handle the case when no data is found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "mAZs66v2xdRY",
        "outputId": "aa26a30d-e2e3-436d-8b4b-866e58571834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0b1c5e67225e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msplit_sehat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_sehat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_sehat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data found in the directory.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'split_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = split_data(dir_sakit)\n",
        "print(\"Plant Label Map:\", label_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "THnp9394-sEP",
        "outputId": "b6f7030b-bcf3-4db3-ac39-5884f263bd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0312b559a525>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_sakit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Plant Label Map:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-217f8920ff9e>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(root_dir, train_size, val_size, test_size, random_seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Membagi data menjadi train, val, dan test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplant_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.15000000000000002 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cek direktori"
      ],
      "metadata": {
        "id": "uXZGTCXvwQcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cek_dir(root_dir):\n",
        "  ada_sub_direktori_kosong = False  # Inisialisasi flag\n",
        "  for rootdir, dirs, files in os.walk(root_dir):\n",
        "      for subdir in reversed(dirs):\n",
        "          subdir_path = os.path.join(rootdir, subdir)\n",
        "          if len(os.listdir(subdir_path)) == 0:\n",
        "              print(f\"Sub-direktori kosong: {subdir_path}\")\n",
        "              dirs.remove(subdir)\n",
        "              os.rmdir(subdir_path)\n",
        "          else:\n",
        "                print(f\"Sub-direktori berisi file: {subdir_path}\")\n",
        "  # Cek flag dan cetak pesan sesuai\n",
        "  if not ada_sub_direktori_kosong:\n",
        "    print(\"Tidak ada sub-direktori kosong.\")"
      ],
      "metadata": {
        "id": "q5PLQYcx2muR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cek_dir(dir_sehat)\n",
        "print(\"\\n\")\n",
        "cek_dir(dir_sakit)\n"
      ],
      "metadata": {
        "id": "mpCpAhjhsWo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ee8593-c773-4551-a192-e0ce8cbda24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/kol\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/selada\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/daun timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/sawi\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/bok choy\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/tomato\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/daun tomat\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/kol\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/selada\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/daun timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/sawi\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/bok choy\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/tomato\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/train/daun tomat\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/kol\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/selada\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/daun timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/sawi\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/bok choy\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/tomato\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/val/daun tomat\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/kol\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/selada\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/daun timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/timun\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/sawi\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/bok choy\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/tomato\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sehat/test/daun tomat\n",
            "Tidak ada sub-direktori kosong.\n",
            "\n",
            "\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/test\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/val\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/train\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/unhealthy leaf\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/unhealhty fruit\n",
            "Sub-direktori kosong: /content/drive/MyDrive/new dataset/sakit/train/train\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/train/unhealthy leaf\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/train/unhealhty fruit\n",
            "Sub-direktori kosong: /content/drive/MyDrive/new dataset/sakit/val/train\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/val/unhealthy leaf\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/val/unhealhty fruit\n",
            "Sub-direktori kosong: /content/drive/MyDrive/new dataset/sakit/test/train\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/test/unhealthy leaf\n",
            "Sub-direktori berisi file: /content/drive/MyDrive/new dataset/sakit/test/unhealhty fruit\n",
            "Tidak ada sub-direktori kosong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loop melalui setiap folder train dan tampilkan jumlah data\n",
        "def cek_train(train_dir):\n",
        "  for plant_folder in os.listdir(train_dir):\n",
        "      plant_path = os.path.join(train_dir, plant_folder)\n",
        "\n",
        "      if os.path.isdir(plant_path):\n",
        "          num_train_data = len(os.listdir(plant_path))\n",
        "          print(f\"Train data for {plant_folder}: {num_train_data} images\")\n",
        "\n",
        "# Loop melalui setiap folder validation dan tampilkan jumlah data\n",
        "def cek_val(val_dir):\n",
        "  for plant_folder in os.listdir(val_dir):\n",
        "      plant_path = os.path.join(val_dir, plant_folder)\n",
        "\n",
        "      if os.path.isdir(plant_path):\n",
        "          num_val_data = len(os.listdir(plant_path))\n",
        "          print(f\"Validation data for {plant_folder}: {num_val_data} images\")\n",
        "\n",
        "# Loop melalui setiap folder test dan tampilkan jumlah data\n",
        "def cek_val(val_dir):\n",
        "  for plant_folder in os.listdir(val_dir):\n",
        "      plant_path = os.path.join(val_dir, plant_folder)\n",
        "\n",
        "      if os.path.isdir(plant_path):\n",
        "          num_val_data = len(os.listdir(plant_path))\n",
        "          print(f\"test data for {plant_folder}: {num_val_data} images\")"
      ],
      "metadata": {
        "id": "eyp1MGoOwUAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sehat = '/content/drive/MyDrive/new dataset/sehat/train'\n",
        "val_sehat = '/content/drive/MyDrive/new dataset/sehat/val'\n",
        "test_sehat = '/content/drive/MyDrive/new dataset/sehat/test'\n",
        "train_sakit = '/content/drive/MyDrive/new dataset/sakit/train'\n",
        "val_sakit = '/content/drive/MyDrive/new dataset/sakit/val'\n",
        "test_sakit = '/content/drive/MyDrive/new dataset/sakit/test'\n",
        "\n",
        "cek_train(train_sehat)\n",
        "print(\"\\n\")\n",
        "cek_val(val_sehat)\n",
        "print(\"\\n\")\n",
        "cek_val(test_sehat)\n",
        "print(\"\\n\\n\")\n",
        "cek_train(train_sakit)\n",
        "print(\"\\n\")\n",
        "cek_val(val_sakit)\n",
        "print(\"\\n\")\n",
        "cek_val(test_sakit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEUBDKXH_lDV",
        "outputId": "988220da-b0f6-4df0-d0d7-0dab9bd404c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data for daun tomat: 181 images\n",
            "Train data for tomato: 157 images\n",
            "Train data for bok choy: 173 images\n",
            "Train data for sawi: 196 images\n",
            "Train data for timun: 207 images\n",
            "Train data for daun timun: 192 images\n",
            "Train data for selada: 174 images\n",
            "Train data for kol: 188 images\n",
            "\n",
            "\n",
            "test data for daun tomat: 22 images\n",
            "test data for tomato: 24 images\n",
            "test data for bok choy: 20 images\n",
            "test data for sawi: 23 images\n",
            "test data for timun: 25 images\n",
            "test data for daun timun: 22 images\n",
            "test data for selada: 21 images\n",
            "test data for kol: 22 images\n",
            "\n",
            "\n",
            "test data for daun tomat: 14 images\n",
            "test data for tomato: 17 images\n",
            "test data for bok choy: 14 images\n",
            "test data for sawi: 16 images\n",
            "test data for timun: 20 images\n",
            "test data for daun timun: 19 images\n",
            "test data for selada: 16 images\n",
            "test data for kol: 16 images\n",
            "\n",
            "\n",
            "\n",
            "Train data for unhealhty fruit: 204 images\n",
            "Train data for unhealthy leaf: 316 images\n",
            "\n",
            "\n",
            "test data for unhealhty fruit: 27 images\n",
            "test data for unhealthy leaf: 40 images\n",
            "\n",
            "\n",
            "test data for unhealhty fruit: 28 images\n",
            "test data for unhealthy leaf: 42 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Data Generator"
      ],
      "metadata": {
        "id": "EZDxukSCzT05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**training datagen untuk tanaman sehat**"
      ],
      "metadata": {
        "id": "8ew18jAmDLjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Tentukan path direktori data tanaman dan penyakit\n",
        "train_dir_plant = '/content/drive/MyDrive/new dataset/sehat/train'\n",
        "train_dir_disease = '/content/drive/MyDrive/new dataset/sakit/train'\n",
        "validation_dir_plant = '/content/drive/MyDrive/new dataset/sehat/val'\n",
        "validation_dir_disease = '/content/drive/MyDrive/new dataset/sakit/val'\n",
        "test_dir_plant = '/content/drive/MyDrive/new dataset/sehat/test'\n",
        "test_dir_disease = '/content/drive/MyDrive/new dataset/sakit/test'\n",
        "\n",
        "# Inisialisasi ImageDataGenerator untuk augmentasi dan normalisasi data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Gunakan flow_from_directory untuk memuat data dari direktori\n",
        "train_generator_plant = train_datagen.flow_from_directory(\n",
        "    train_dir_plant,\n",
        "    target_size=(150, 150, 3),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Sesuaikan dengan tipe klasifikasi yang Anda lakukan\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator_plant = validation_datagen.flow_from_directory(\n",
        "    validation_dir_plant,\n",
        "    target_size=(150, 150, 3),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator_plant = test_datagen.flow_from_directory(\n",
        "    test_dir_plant,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "train_generator_disease = train_datagen.flow_from_directory(\n",
        "    train_dir_disease,\n",
        "    target_size=(150, 150, 3),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator_disease = validation_datagen.flow_from_directory(\n",
        "    validation_dir_disease,\n",
        "    target_size=(150, 150, 3),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator_disease = test_datagen.flow_from_directory(\n",
        "    test_dir_disease,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "LgfPMSHo5FuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b11c328-dc64-4450-971f-e909f56b6c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1468 images belonging to 8 classes.\n",
            "Found 179 images belonging to 8 classes.\n",
            "Found 132 images belonging to 8 classes.\n",
            "Found 520 images belonging to 2 classes.\n",
            "Found 67 images belonging to 2 classes.\n",
            "Found 70 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**training datagen untuk tanaman sakit**"
      ],
      "metadata": {
        "id": "CL2x5AYfDdq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINE MODEL**"
      ],
      "metadata": {
        "id": "UmrbphSa5yku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "10fc5SdMzZo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "YR4Aw74pQGSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_jenis_tanaman():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "  ])\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "# Print the model summary\n",
        "model_tanaman = model_jenis_tanaman()\n",
        "model_tanaman.summary()"
      ],
      "metadata": {
        "id": "ZMNTEZja5uyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6edb8f-d6b9-4710-b2dd-232c7828a85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 148, 148, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 74, 74, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 72, 72, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 34, 34, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 17, 17, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9248)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 9248)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               1183872   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280744 (4.89 MB)\n",
            "Trainable params: 1280744 (4.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Assuming output_dim_model1 is the number of features in the output of model_tanaman\n",
        "output_dim_model1 = model_tanaman.output_shape[1]"
      ],
      "metadata": {
        "id": "S65im1vmJn0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_deteksi_penyakit():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(output_dim_model1 , output_dim_model1 , 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The 4 convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "  ])\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Print the model summary\n",
        "model_penyakit = model_deteksi_penyakit()\n",
        "model_penyakit.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "BrBvN3ZYDvTs",
        "outputId": "1aa47a23-3280-405a-e06e-517c0558f243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2c0c3e2afcb8>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Print the model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel_penyakit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_deteksi_penyakit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodel_penyakit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-2c0c3e2afcb8>\u001b[0m in \u001b[0;36mmodel_deteksi_penyakit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_deteksi_penyakit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   model = tf.keras.models.Sequential([\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# This is the first convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim_model1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput_dim_model1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_14\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_14/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n\nCall arguments received by layer \"max_pooling2d_14\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training Model"
      ],
      "metadata": {
        "id": "KWr4MuJhzee-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      # Check the loss\n",
        "      if(logs.get('loss') < 0.5 or logs.get('accuracy') > 0.8):\n",
        "\n",
        "        # Stop if threshold is met\n",
        "        print(\"\\nLoss is lower than 0.4 and acc is above 0.8 so cancelling training!\")\n",
        "        self.model.stop_training = True\n",
        "        print(f'Epoch {epoch} ended with logs: {logs}')\n",
        "# Instantiate class\n",
        "callbacks = Callback()"
      ],
      "metadata": {
        "id": "5GdxUv3fluFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train tanaman\n",
        "model_tanaman.fit(train_generator_plant,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator_plant,\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "H5pHGa5v52nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train tanaman sakit\n",
        "model_penyakit.fit(train_generator_disease,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator_disease,\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "RGpoRZGrAmFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nama_tanaman = ['bok choy', 'daun timun', 'daun tomat', 'kol', 'sawi', 'selada', 'timun', 'tomat']\n",
        "# Assuming `penyakit` is your first model and `model_penyakit` is the second model\n",
        "# Assuming `train_generator_sakit` and `validation_generator_sakit` are your data generators\n",
        "\n",
        "# Train the first model\n",
        "model_tanaman.fit(train_generator_plant, epochs=20, verbose=1, validation_data=validation_generator_plant, callbacks=[callbacks])\n",
        "\n",
        "# Train the second model\n",
        "model_penyakit.fit(train_generator_disease, epochs=20, verbose=1, validation_data=validation_generator_disease, callbacks=[callbacks])\n",
        "\n",
        "# Get predictions from the two models\n",
        "predictions_penyakit_train = model_penyakit.predict(train_generator_plant)\n",
        "predictions_model_penyakit_train = model_penyakit.predict(train_generator_disease)\n",
        "\n",
        "# Stack the predictions horizontally\n",
        "stacked_predictions_train = np.hstack((predictions_penyakit_train, predictions_model_penyakit_train))\n",
        "\n",
        "# Create a logistic regression model for stacking\n",
        "stacking_model = StackingClassifier(estimators=[('tanaman', model_tanaman), ('penyakit', model_penyakit)],\n",
        "                                    final_estimator=LogisticRegression())\n",
        "\n",
        "# Train the stacking model on the stacked predictions\n",
        "stacking_model.fit(stacked_predictions_train, target_variable_for_training)\n",
        "\n",
        "# Now you can use the stacking model for predictions on new data\n",
        "# Repeat the process for validation data and test data if needed\n"
      ],
      "metadata": {
        "id": "D_DWLdBT_UwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Model tanaman"
      ],
      "metadata": {
        "id": "Zlt_O_Jzz1fG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rename file agar mudah terbaca**"
      ],
      "metadata": {
        "id": "adoIsZIQlBDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rename(directory_):\n",
        "  for folder_name in os.listdir(directory_):\n",
        "      # Mendapatkan path lengkap folder\n",
        "      folder_path = os.path.join(directory_, folder_name)\n",
        "\n",
        "      # Memeriksa apakah itu benar-benar folder\n",
        "      if os.path.isdir(folder_path):\n",
        "          # Mendapatkan daftar file dalam folder\n",
        "          files = os.listdir(folder_path)\n",
        "\n",
        "          # Mengurutkan file\n",
        "          files.sort()\n",
        "\n",
        "          # Mengganti nama file sesuai dengan nama folder dan urutan\n",
        "          for i, file_name in enumerate(files):\n",
        "              # Membentuk nama baru\n",
        "              new_name = f\"{folder_name}_{i + 1}{os.path.splitext(file_name)[1]}\"\n",
        "\n",
        "              # Path file lama dan baru\n",
        "              old_path = os.path.join(folder_path, file_name)\n",
        "              new_path = os.path.join(folder_path, new_name)\n",
        "\n",
        "              # Mengganti nama file\n",
        "              os.rename(old_path, new_path)"
      ],
      "metadata": {
        "id": "rpqqvc-OiDpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename('/content/drive/MyDrive/new dataset/sehat/test')\n",
        "rename('/content/drive/MyDrive/new dataset/sakit/test')\n"
      ],
      "metadata": {
        "id": "6CjtZZ9L0OAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sehat_test_dir ='/content/drive/MyDrive/new dataset/sehat/test'\n",
        "# Buat objek ImageDataGenerator untuk memuat gambar dari direktori\n",
        "test_datagen_sehat = ImageDataGenerator(rescale=1./255)\n",
        "test_generator_sehat = test_datagen_sehat.flow_from_directory(\n",
        "    sehat_test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',  # Sesuaikan dengan jenis kelas data Anda\n",
        "    shuffle=False  # Pastikan tidak ada pengacakan data\n",
        "  )\n",
        "\n",
        "sakit_test_dir ='/content/drive/MyDrive/new dataset/sakit/test'\n",
        "# Buat objek ImageDataGenerator untuk memuat gambar dari direktori\n",
        "test_datagen_sakit = ImageDataGenerator(rescale=1./255)\n",
        "test_generator_sakit = test_datagen_sakit.flow_from_directory(\n",
        "    sakit_test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',  # Sesuaikan dengan jenis kelas data Anda\n",
        "    shuffle=False  # Pastikan tidak ada pengacakan data\n",
        "  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgJDIKV3M2WV",
        "outputId": "5e8ca29c-6175-4942-a193-d5575537e603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39 images belonging to 8 classes.\n",
            "Found 35 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan prediksi untuk setiap gambar dalam direktori test\n",
        "predictions = jenis_tanaman.predict(test_generator_sehat)\n",
        "nama_tanaman = ['bok choy', 'daun timun', 'daun tomat', 'kol', 'sawi', 'selada', 'timun', 'tomat']\n",
        "results = []\n",
        "for i, prediction in enumerate(predictions):\n",
        "    # Ambil nama file gambar\n",
        "    image_filename = os.path.basename(test_generator_sehat.filenames[i])\n",
        "\n",
        "    # Ambil indeks hasil prediksi\n",
        "    predicted_index = np.argmax(prediction)\n",
        "\n",
        "    # Ganti hasil prediksi dengan nama buah sesuai indeks\n",
        "    predicted_label = nama_tanaman[predicted_index]\n",
        "\n",
        "    # Simpan pasangan (nama file, hasil prediksi) dalam list\n",
        "    results.append((image_filename, predicted_label))\n",
        "\n",
        "# Urutkan berdasarkan nama file\n",
        "results.sort(key=lambda x: x[0])\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "for i, (image_filename, predicted_label) in enumerate(results):\n",
        "    # Dapatkan path lengkap untuk gambar\n",
        "    image_path = os.path.join(sehat_test_dir, image_filename)\n",
        "\n",
        "    # Tampilkan hasil prediksi\n",
        "    print(f\"Gambar {i + 1} - nama file: {image_filename}, Prediksi: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6tjMr_jdmEQ",
        "outputId": "a4bc6932-6382-4264-800d-2ccabbbfb718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 2s 39ms/step\n",
            "Gambar 1 - nama file: bok choy_1.jpg, Prediksi: selada\n",
            "Gambar 2 - nama file: bok choy_2.jpg, Prediksi: bok choy\n",
            "Gambar 3 - nama file: bok choy_3.jpg, Prediksi: timun\n",
            "Gambar 4 - nama file: daun timun_1.jpg, Prediksi: daun timun\n",
            "Gambar 5 - nama file: daun timun_2.jpg, Prediksi: sawi\n",
            "Gambar 6 - nama file: daun timun_3.jpg, Prediksi: daun timun\n",
            "Gambar 7 - nama file: daun timun_4.jpg, Prediksi: daun timun\n",
            "Gambar 8 - nama file: daun timun_5.JPG, Prediksi: kol\n",
            "Gambar 9 - nama file: daun timun_6.JPG, Prediksi: daun timun\n",
            "Gambar 10 - nama file: daun timun_7.JPG, Prediksi: kol\n",
            "Gambar 11 - nama file: daun tomat_1.JPG, Prediksi: daun tomat\n",
            "Gambar 12 - nama file: daun tomat_2.JPG, Prediksi: daun tomat\n",
            "Gambar 13 - nama file: daun tomat_3.JPG, Prediksi: daun tomat\n",
            "Gambar 14 - nama file: kol_1.jpg, Prediksi: kol\n",
            "Gambar 15 - nama file: kol_2.jpg, Prediksi: kol\n",
            "Gambar 16 - nama file: kol_3.jpg, Prediksi: kol\n",
            "Gambar 17 - nama file: kol_4.jpg, Prediksi: kol\n",
            "Gambar 18 - nama file: sawi_1.jpg, Prediksi: kol\n",
            "Gambar 19 - nama file: sawi_2.jpg, Prediksi: sawi\n",
            "Gambar 20 - nama file: sawi_3.jpg, Prediksi: sawi\n",
            "Gambar 21 - nama file: sawi_4.jpg, Prediksi: sawi\n",
            "Gambar 22 - nama file: selada_1.jpg, Prediksi: selada\n",
            "Gambar 23 - nama file: selada_2.png, Prediksi: timun\n",
            "Gambar 24 - nama file: selada_3.png, Prediksi: selada\n",
            "Gambar 25 - nama file: selada_4.jpg, Prediksi: selada\n",
            "Gambar 26 - nama file: selada_5.jpg, Prediksi: selada\n",
            "Gambar 27 - nama file: timun_1.jpg, Prediksi: kol\n",
            "Gambar 28 - nama file: timun_2.jpg, Prediksi: daun timun\n",
            "Gambar 29 - nama file: timun_3.jpg, Prediksi: timun\n",
            "Gambar 30 - nama file: timun_4.jpg, Prediksi: timun\n",
            "Gambar 31 - nama file: timun_5.jpg, Prediksi: timun\n",
            "Gambar 32 - nama file: timun_6.JPG, Prediksi: kol\n",
            "Gambar 33 - nama file: timun_7.png, Prediksi: kol\n",
            "Gambar 34 - nama file: tomato_1.jpg, Prediksi: tomat\n",
            "Gambar 35 - nama file: tomato_2.png, Prediksi: tomat\n",
            "Gambar 36 - nama file: tomato_3.jpg, Prediksi: tomat\n",
            "Gambar 37 - nama file: tomato_4.png, Prediksi: tomat\n",
            "Gambar 38 - nama file: tomato_5.jpeg, Prediksi: tomat\n",
            "Gambar 39 - nama file: tomato_6.jpg, Prediksi: tomat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan prediksi untuk setiap gambar dalam direktori test\n",
        "predictions = penyakit.predict(test_generator_sakit)\n",
        "jenis_penyakit = ['buah busuk', 'daun rusak']\n",
        "results = []\n",
        "for i, prediction in enumerate(predictions):\n",
        "    # Ambil nama file gambar\n",
        "    image_filename = os.path.basename(test_generator_sakit.filenames[i])\n",
        "\n",
        "    # Ambil indeks hasil prediksi\n",
        "    predicted_index = np.argmax(prediction)\n",
        "\n",
        "    # Ganti hasil prediksi dengan nama buah sesuai indeks\n",
        "    predicted_label = jenis_penyakit[predicted_index]\n",
        "\n",
        "    # Simpan pasangan (nama file, hasil prediksi) dalam list\n",
        "    results.append((image_filename, predicted_label))\n",
        "\n",
        "# Urutkan berdasarkan nama file\n",
        "results.sort(key=lambda x: x[0])\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "for i, (image_filename, predicted_label) in enumerate(results):\n",
        "    # Dapatkan path lengkap untuk gambar\n",
        "    image_path = os.path.join(sakit_test_dir, image_filename)\n",
        "\n",
        "    # Tampilkan hasil prediksi\n",
        "    print(f\"Gambar {i + 1} - nama file: {image_filename}, Prediksi: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xsFL5yGPChv",
        "outputId": "a13b7a94-d1de-48a0-e5df-960a8d93750d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 2s 47ms/step\n",
            "Gambar 1 - nama file: unhealhty fruit_1.jpg, Prediksi: buah busuk\n",
            "Gambar 2 - nama file: unhealhty fruit_10.jpg, Prediksi: daun rusak\n",
            "Gambar 3 - nama file: unhealhty fruit_11.jpg, Prediksi: buah busuk\n",
            "Gambar 4 - nama file: unhealhty fruit_12.jpg, Prediksi: buah busuk\n",
            "Gambar 5 - nama file: unhealhty fruit_13.jpg, Prediksi: buah busuk\n",
            "Gambar 6 - nama file: unhealhty fruit_14.jpg, Prediksi: buah busuk\n",
            "Gambar 7 - nama file: unhealhty fruit_2.jpg, Prediksi: buah busuk\n",
            "Gambar 8 - nama file: unhealhty fruit_3.jpg, Prediksi: buah busuk\n",
            "Gambar 9 - nama file: unhealhty fruit_4.jpg, Prediksi: daun rusak\n",
            "Gambar 10 - nama file: unhealhty fruit_5.jpg, Prediksi: buah busuk\n",
            "Gambar 11 - nama file: unhealhty fruit_6.jpg, Prediksi: buah busuk\n",
            "Gambar 12 - nama file: unhealhty fruit_7.jpg, Prediksi: buah busuk\n",
            "Gambar 13 - nama file: unhealhty fruit_8.jpg, Prediksi: buah busuk\n",
            "Gambar 14 - nama file: unhealhty fruit_9.jpg, Prediksi: buah busuk\n",
            "Gambar 15 - nama file: unhealthy leaf_1.JPG, Prediksi: daun rusak\n",
            "Gambar 16 - nama file: unhealthy leaf_10.jpg, Prediksi: daun rusak\n",
            "Gambar 17 - nama file: unhealthy leaf_11.JPG, Prediksi: daun rusak\n",
            "Gambar 18 - nama file: unhealthy leaf_12.jpg, Prediksi: daun rusak\n",
            "Gambar 19 - nama file: unhealthy leaf_13.jpg, Prediksi: daun rusak\n",
            "Gambar 20 - nama file: unhealthy leaf_14.jpg, Prediksi: daun rusak\n",
            "Gambar 21 - nama file: unhealthy leaf_15.jpg, Prediksi: daun rusak\n",
            "Gambar 22 - nama file: unhealthy leaf_16.jpg, Prediksi: daun rusak\n",
            "Gambar 23 - nama file: unhealthy leaf_17.jpg, Prediksi: daun rusak\n",
            "Gambar 24 - nama file: unhealthy leaf_18.jpg, Prediksi: daun rusak\n",
            "Gambar 25 - nama file: unhealthy leaf_19.jpg, Prediksi: daun rusak\n",
            "Gambar 26 - nama file: unhealthy leaf_2.jpg, Prediksi: daun rusak\n",
            "Gambar 27 - nama file: unhealthy leaf_20.jpg, Prediksi: daun rusak\n",
            "Gambar 28 - nama file: unhealthy leaf_21.jpg, Prediksi: daun rusak\n",
            "Gambar 29 - nama file: unhealthy leaf_3.jpg, Prediksi: daun rusak\n",
            "Gambar 30 - nama file: unhealthy leaf_4.jpg, Prediksi: daun rusak\n",
            "Gambar 31 - nama file: unhealthy leaf_5.JPG, Prediksi: daun rusak\n",
            "Gambar 32 - nama file: unhealthy leaf_6.jpg, Prediksi: daun rusak\n",
            "Gambar 33 - nama file: unhealthy leaf_7.jpg, Prediksi: buah busuk\n",
            "Gambar 34 - nama file: unhealthy leaf_8.jpg, Prediksi: daun rusak\n",
            "Gambar 35 - nama file: unhealthy leaf_9.jpg, Prediksi: daun rusak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict gabungan**"
      ],
      "metadata": {
        "id": "NDfXdxr5S9q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan prediksi untuk setiap gambar dalam direktori test\n",
        "predictions = combined_model.predict([test_generator_sehat, test_generator_sakit])\n",
        "nama_tanaman = ['bok choy', 'daun timun', 'daun tomat', 'kol', 'sawi', 'selada', 'timun', 'tomat']\n",
        "jenis_penyakit = ['tanpa penyakit', 'dengan penyakit']\n",
        "results = []\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    # Ambil nama file gambar dari generator yang sesuai\n",
        "    if i < len(test_generator_sehat.filenames):\n",
        "        image_filename = os.path.basename(test_generator_sehat.filenames[i])\n",
        "    else:\n",
        "        image_filename = os.path.basename(test_generator_sakit.filenames[i - len(test_generator_sehat.filenames)])\n",
        "\n",
        "    # Ambil indeks hasil prediksi\n",
        "    predicted_index = np.argmax(prediction)\n",
        "\n",
        "    # Ganti hasil prediksi dengan nama buah sesuai indeks\n",
        "    predicted_label = jenis_penyakit[predicted_index]\n",
        "\n",
        "    # Simpan pasangan (nama file, hasil prediksi) dalam list\n",
        "    results.append((image_filename, predicted_label))\n",
        "\n",
        "# Urutkan berdasarkan nama file\n",
        "results.sort(key=lambda x: x[0])\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "for i, (image_filename, predicted_label) in enumerate(results):\n",
        "    # Dapatkan path lengkap untuk gambar\n",
        "    if i < len(test_generator_sehat.filenames):\n",
        "        image_path = os.path.join(sehat_test_dir, image_filename)\n",
        "    else:\n",
        "        image_path = os.path.join(sakit_test_dir, image_filename)\n",
        "\n",
        "    # Tampilkan hasil prediksi\n",
        "    print(f\"Gambar {i + 1} - nama file: {image_filename}, Prediksi: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "az8bkONnQh0D",
        "outputId": "99433925-db2c-460a-f797-c842ab9f7e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b8117d89ca04>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lakukan prediksi untuk setiap gambar dalam direktori test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_generator_sehat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator_sakit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnama_tanaman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bok choy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daun timun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daun tomat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sawi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'selada'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tomat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjenis_penyakit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tanpa penyakit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dengan penyakit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'keras.src.preprocessing.image.DirectoryIterator'>\"}), <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H1xa2M8qS8KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ploting Training\n"
      ],
      "metadata": {
        "id": "qe2ScZEAzvd7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE3g9nxRz-g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "qrI2W3Vu0Pil"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lkwCU_w0VUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}